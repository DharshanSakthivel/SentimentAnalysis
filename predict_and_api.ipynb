{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6ad0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_and_api.py\n",
    "\n",
    "import torch\n",
    "import joblib\n",
    "import shutil\n",
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import uvicorn\n",
    "import re, emoji, string\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# ======= Clear Hugging Face Transformers Cache =======\n",
    "hf_cache_dir = os.path.expanduser(\"~/.cache/huggingface/transformers\")\n",
    "if os.path.exists(hf_cache_dir):\n",
    "    print(\"\\nðŸ§¹ Clearing Hugging Face Transformers cache...\")\n",
    "    shutil.rmtree(hf_cache_dir)\n",
    "    print(\"âœ… Cache cleared successfully.\\n\")\n",
    "\n",
    "# ======= Preprocessing Utils =======\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.difference_update({\"no\", \"not\", \"don\", \"shouldn\", \"wasn\", \"mustn\"})\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "emoticon_dict = {\n",
    "    \":)\": \"smiley\", \":-)\": \"smiley\", \":D\": \"laugh\", \":-D\": \"laugh\",\n",
    "    \":(\": \"sad\", \":-(\": \"sad\", \":'(\": \"cry\", \":'-\\(\": \"cry\",\n",
    "    \":P\": \"playful\", \":-P\": \"playful\", \";)\": \"wink\", \";-)\": \"wink\",\n",
    "    \":/\": \"skeptical\", \":-/\": \"skeptical\", \":|\": \"neutral\", \":-|\": \"neutral\",\n",
    "    \":O\": \"surprised\", \":-O\": \"surprised\", \"XD\": \"laugh\", \"<3\": \"love\",\n",
    "    \">:(\": \"angry\", \"D:\": \"horrified\", \":-*\": \"kiss\", \":3\": \"cute\",\n",
    "    \":-X\": \"sealed lips\", \"B-)\": \"cool\", \"O:)\": \"angel\", \">:)\": \"evil smile\"\n",
    "}\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"link\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"user_mention\", text)\n",
    "    text = re.sub(r\"#(\\w+)\", lambda m: m.group(1).replace(\"_\", \" \"), text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    for emot, meaning in emoticon_dict.items():\n",
    "        text = text.replace(emot, f\" {meaning} \")\n",
    "    text = emoji.demojize(text).replace(\":\", \"\").replace(\"_\", \" \")\n",
    "    text = re.sub(rf\"[{string.punctuation}]\", \"\", text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [stemmer.stem(lemmatizer.lemmatize(w)) for w in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ======= Load Models =======\n",
    "traditional_models = {\n",
    "    \"nb_count\": joblib.load(\"C:/DCS/saved_models/saved_models/traditional/nb_count_bi.joblib\"),\n",
    "    \"lr_count\": joblib.load(\"C:/DCS/saved_models/saved_models/traditional/lr_count_bi.joblib\"),\n",
    "    \"svm_count\": joblib.load(\"C:/DCS/saved_models/saved_models/traditional/svm_count_bi.joblib\")\n",
    "}\n",
    "\n",
    "transformer_models = {\n",
    "    \"distilbert\": {\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/distilbert-base-uncased\", local_files_only=True),\n",
    "        \"model\": AutoModelForSequenceClassification.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/distilbert-base-uncased\", local_files_only=True)\n",
    "    },\n",
    "    \"bert-base\": {\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/bert-base-uncased\", local_files_only=True),\n",
    "        \"model\": AutoModelForSequenceClassification.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/bert-base-uncased\", local_files_only=True)\n",
    "    },\n",
    "    # \"bert-large\": {\n",
    "    #     \"tokenizer\": AutoTokenizer.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/bert-large-uncased\", local_files_only=True),\n",
    "    #     \"model\": AutoModelForSequenceClassification.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/bert-large-uncased\", local_files_only=True)\n",
    "    # },\n",
    "    # \"roberta\": {\n",
    "    #     \"tokenizer\": AutoTokenizer.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/roberta-base\", local_files_only=True),\n",
    "    #     \"model\": AutoModelForSequenceClassification.from_pretrained(\"C:/DCS/saved_models/saved_models/transformers/roberta-base\", local_files_only=True)\n",
    "    # }\n",
    "}\n",
    "\n",
    "# ======= API Schema =======\n",
    "class TextInput(BaseModel):\n",
    "    text: str\n",
    "    model: str  # e.g., \"nb_count\", \"lr_count\", \"svm_count\", \"distilbert\", \"bert-base\"\n",
    "\n",
    "# ======= Prediction Endpoint =======\n",
    "@app.post(\"/predict\")\n",
    "def predict_sentiment(input_data: TextInput):\n",
    "    text = preprocess(input_data.text)\n",
    "    model_key = input_data.model\n",
    "\n",
    "    if model_key in traditional_models:\n",
    "        model, vectorizer = traditional_models[model_key]\n",
    "        vec = vectorizer.transform([text])\n",
    "        pred = model.predict(vec)[0]\n",
    "        return {\"sentiment\": \"positive\" if pred == 1 else \"negative\"}\n",
    "\n",
    "    elif model_key in transformer_models:\n",
    "        tokenizer = transformer_models[model_key][\"tokenizer\"]\n",
    "        model = transformer_models[model_key][\"model\"]\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "            outputs = model(**inputs)\n",
    "            pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "        return {\"sentiment\": \"positive\" if pred == 1 else \"negative\"}\n",
    "\n",
    "    else:\n",
    "        return {\"error\": \"Model not found or not supported.\"}\n",
    "\n",
    "# To run this server:\n",
    "# uvicorn predict_and_api:app --reload\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
